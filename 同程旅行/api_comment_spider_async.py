import csv
import json
import os
import random
import threading
import time
from datetime import datetime
import execjs
import requests
API_URL = "https://www.ly.com/tapi/getCommentList"
PROXY_API_URL = ""
PROXY_USERNAME = ""
PROXY_PASSWORD = ""
USER_AGENTS = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 12_3_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 11.6; rv:122.0) Gecko/20100101 Firefox/122.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 12_3) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.3 Safari/605.1.15",
]
lock_print = threading.Lock()
def log(msg: str):
    with lock_print:
        print(msg, flush=True)
def ts_to_datetime(ts):
    if not ts:
        return ""
    try:
        if isinstance(ts, str):
            ts = int(ts)
        if ts > 10000000000:
            ts = ts / 1000
        return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return str(ts)
def get_proxy():
    try:
        proxy_ip = requests.get(PROXY_API_URL, timeout=10).text.strip()
        if proxy_ip:
            proxies = {
                "http": f"http://{PROXY_USERNAME}:{PROXY_PASSWORD}@{proxy_ip}/",
                "https": f"http://{PROXY_USERNAME}:{PROXY_PASSWORD}@{proxy_ip}/",
            }
            log(f"  ğŸŒ è·å–ä»£ç†: {proxy_ip}")
            return proxies
    except Exception as e:
        log(f"  âš ï¸ è·å–ä»£ç†å¤±è´¥: {e}")
    return None
def get_random_headers(hotel_id: str):
    ua = random.choice(USER_AGENTS)
    platform = '"macOS"' if "Macintosh" in ua else '"Windows"' if "Windows" in ua else '"Android"'
    return {
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "Pragma": "no-cache",
        "Referer": f"https://www.ly.com/hotel/hoteldetail?hotelId={hotel_id}&inDate=2025-12-17&outDate=2025-12-18&adultsNumber=1",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": ua,
        "appfrom": "16",
        "lang": "zh-cn",
        "pageName": "hoteldetail",
        "sec-ch-ua": '"Google Chrome";v="120", "Chromium";v="120", "Not A(Brand";v="24"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": platform,
        "timeZone": "8",
        "tmapi-client": "tpc",
    }
def load_user_dun_ctx():
    with open("./userDun.js", encoding="utf-8") as f:
        js_code = f.read()
    return execjs.compile(js_code)
def build_params(hotel_id: str, page_index: int, sort_method: str = "latest") -> dict:
    """
    æ„å»ºè¯·æ±‚å‚æ•°
    :param hotel_id: é…’åº—ID
    :param page_index: é¡µç 
    :param sort_method: æ’åºæ–¹å¼ï¼Œ"latest" ä¸ºæœ€æ–°æ’åºï¼Œ"comprehensive" ä¸ºç»¼åˆæ’åº
    """
    # sortingMethod: 0=æœ€æ–°æ’åº, 1=ç»¼åˆæ’åº
    sorting_method = 0 if sort_method == "latest" else 1
    body = {
        "objectId": hotel_id,
        "keyword": "",
        "pageSize": 10,
        "sortingInfo": {"sortingMethod": sorting_method, "sortingDirection": 1},
        "traceToken": "",
        # ä¹‹å‰è¿™é‡ŒåŠ äº† searchFeatures + filterIds=["1"]ï¼Œç›¸å½“äºåšäº†è¿‡æ»¤ï¼Œåªæ‹¿åˆ°ä¸€éƒ¨åˆ†è¯„è®º
        # ä¸ºäº†å’Œç½‘é¡µé»˜è®¤â€œå…¨éƒ¨è¯„è®ºâ€çš„æ•°é‡ä¸€è‡´ï¼Œè¿™é‡ŒæŠŠè¿‡æ»¤æ¡ä»¶å»æ‰
        "searchFeatures": [],
        "pageIndex": page_index,
    }
    return {"bodyStr": json.dumps(body, ensure_ascii=False)}
def gen_user_dun(ctx, params: dict) -> str:
    query = "&".join([f"{k}={v}" for k, v in params.items()])
    url = f"{API_URL}?{query}"
    return ctx.call("main123", url)
def fetch_page(ctx, hotel_id: str, page_index: int, proxies=None, retry: int = 3, silent: bool = False, sort_method: str = "latest"):
    params = build_params(hotel_id, page_index, sort_method)
    user_dun = gen_user_dun(ctx, params)
    headers = get_random_headers(hotel_id)
    headers["User-Dun"] = user_dun
    for attempt in range(retry):
        try:
            resp = requests.get(
                API_URL,
                headers=headers,
                params=params,
                proxies=proxies,
                timeout=30,
            )
            break
        except (
            requests.exceptions.Timeout,
            requests.exceptions.ProxyError,
            requests.exceptions.ConnectionError,
        ) as e:
            log(f"    âš ï¸ é…’åº— {hotel_id} ç¬¬ {page_index} é¡µè¯·æ±‚å¤±è´¥({e})ï¼Œé‡è¯• {attempt + 2}/{retry}...")
            proxies = get_proxy()
            time.sleep(random.uniform(1, 2))
    else:
        return [], None
    if resp.status_code != 200:
        if not silent:
            log(f"    âŒ é…’åº— {hotel_id} ç¬¬ {page_index} é¡µçŠ¶æ€ç å¼‚å¸¸: {resp.status_code}")
        return [], None
    try:
        data = resp.json()
    except Exception as e:
        if not silent:
            log(f"    âŒ é…’åº— {hotel_id} ç¬¬ {page_index} é¡µ JSON è§£æå¤±è´¥: {e}")
        return [], None
    d = data.get("data", {}) or {}
    total = d.get("total") or data.get("total")
    comments = d.get("comments", []) or d.get("commentList", [])
    return comments, total
def scrape_hotel(hotel_id: str, sort_method: str = "latest"):
    hotel_id = hotel_id.strip()
    if not hotel_id:
        return
    sort_name = "æœ€æ–°æ’åº" if sort_method == "latest" else "ç»¼åˆæ’åº"
    log(f"\n===== å¼€å§‹æŠ“å–é…’åº— {hotel_id} (æ’åºæ–¹å¼: {sort_name}) =====")
    ctx = load_user_dun_ctx()
    proxies = get_proxy()
    comments0, total = fetch_page(ctx, hotel_id, 0, proxies=proxies, sort_method=sort_method)
    if total is None:
        log(f"é…’åº— {hotel_id} è·å– total å¤±è´¥ï¼Œè·³è¿‡")
        return
    total_pages = (int(total) + 9) // 10
    log(f"é…’åº— {hotel_id} æ€»è¯„è®ºæ•°: {total}, é¢„è®¡é¡µæ•°: {total_pages}")
    os.makedirs("result", exist_ok=True)
    out_path = os.path.join("result", f"{hotel_id}.csv")
    f_csv = open(out_path, "w", newline="", encoding="utf-8-sig")
    writer = csv.writer(f_csv)
    writer.writerow(["é…’åº—ID", "è¯„è®ºID", "è¯„è®ºå†…å®¹", "å•æ¡è¯„åˆ†", "å…¥ä½æ—¶é—´"])
    total_saved = 0
    for page_index in range(total_pages):
        comments = []
        max_empty_retry = 3
        for empty_attempt in range(max_empty_retry):
            comments, _ = fetch_page(
                ctx,
                hotel_id,
                page_index,
                proxies=proxies,
                sort_method=sort_method,
            )
            if comments:
                break
            log(
                f"    âš ï¸ é…’åº— {hotel_id} ç¬¬ {page_index} é¡µè¿”å› 0 æ¡æ•°æ®ï¼Œé‡è¯• {empty_attempt + 1}/{max_empty_retry}..."
            )
            time.sleep(random.uniform(0.5, 1.0))
        if not comments:
            log(f"  é…’åº— {hotel_id} ç¬¬ {page_index} é¡µå¤šæ¬¡æ— æ•°æ®ï¼Œè·³è¿‡è¯¥é¡µ")
            continue
        page_saved = 0
        for c in comments:
            comment_ext = c.get("commentExt") or {}
            order_info = comment_ext.get("order") or {}
            check_in_ts = order_info.get("checkInTime") or c.get("checkInDate") or c.get("date")
            cid = c.get("id") or c.get("commentId") or c.get("cid") or ""
            content = (c.get("content") or c.get("comment") or "").strip()
            score = c.get("commentScore") or c.get("score") or c.get("rating") or ""
            check_in_str = ts_to_datetime(check_in_ts)
            writer.writerow([hotel_id, cid, content, score, check_in_str])
            page_saved += 1
            total_saved += 1
        f_csv.flush()
        log(f"  é…’åº— {hotel_id} ç¬¬ {page_index} é¡µä¿å­˜ {page_saved} æ¡ï¼Œç´¯è®¡ {total_saved} æ¡")
        time.sleep(random.uniform(0.2, 0.6))
    f_csv.close()
    log(f"===== é…’åº— {hotel_id} æŠ“å–å®Œæˆï¼Œå…±ä¿å­˜ {total_saved} æ¡ï¼Œæ–‡ä»¶: {out_path} =====")
def main():
    ids_path = "hotel_ids.txt"
    if not os.path.exists(ids_path):
        log(f"æœªæ‰¾åˆ° {ids_path}")
        return
    with open(ids_path, encoding="utf-8") as f:
        hotel_ids = [line.strip() for line in f if line.strip()]
    if not hotel_ids:
        log("hotel_ids.txt ä¸­æ²¡æœ‰æœ‰æ•ˆé…’åº— ID")
        return
    log("\nè¯·é€‰æ‹©æ’åºæ–¹å¼ï¼š")
    log("1. æœ€æ–°æ’åº (é»˜è®¤)")
    log("2. ç»¼åˆæ’åº")
    choice = input("è¯·è¾“å…¥é€‰é¡¹ (1/2ï¼Œç›´æ¥å›è½¦é»˜è®¤é€‰æ‹©1): ").strip()
    if choice == "2":
        sort_method = "comprehensive"
        sort_name = "ç»¼åˆæ’åº"
    else:
        sort_method = "latest"
        sort_name = "æœ€æ–°æ’åº"
    log(f"\nå·²é€‰æ‹©æ’åºæ–¹å¼: {sort_name}")
    log(f"å…±è¯»å–åˆ° {len(hotel_ids)} ä¸ªé…’åº— IDï¼Œå¼€å§‹ä¾æ¬¡æŠ“å–ï¼ˆå•çº¿ç¨‹ï¼Œé™ä½å¯¹ä»£ç†çš„å‹åŠ›ï¼‰...")
    for hid in hotel_ids:
        try:
            scrape_hotel(hid, sort_method=sort_method)
            time.sleep(1.0)
        except Exception as e:
            log(f"é…’åº— {hid} æŠ“å–å¼‚å¸¸: {e}")
    log("å…¨éƒ¨é…’åº—æŠ“å–å®Œæˆã€‚")
if __name__ == "__main__":
    main()